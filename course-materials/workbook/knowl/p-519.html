<!--**************************************-->
<!--* Generated from MathBook XML source *-->
<!--*    on 2016-10-04T22:24:39-05:00    *-->
<!--*                                    *-->
<!--*   http://mathbook.pugetsound.edu   *-->
<!--*                                    *-->
<!--**************************************-->
<p><h5 class="heading"><span class="type">Paragraph</span></h5>
      Now, how does one understand the Spectral Theorem? It basically guarantees
      that we can always find (a) enough eigenvalues (as real numbers), and (b) for each eigenvalue,
      enough eigenvectors. The hardest parts of the proof come from part (b) where
      you have to produce enough eigenvectors. But in practice, if you have an
      example of a symmetric matrix, you can find the decomposition mentioned in
      the theorem pretty easily. First, find the eigenvalues. Then for each
      eigenvalue \(\lambda\), find an orthonormal basis for the
      <em class="terminology">eigenspace</em>
      \begin{equation*}E_{\lambda} = \mathrm{null}(A-\lambda\cdot I).\end{equation*}
      That second bit can be done in two steps, first find a basis for \(E_{\lambda}\)
      (special solutions!) and then apply the Gram-Schmidt algorithm to find an
      orthonormal basis for \(E_{\lambda}\). Collecting all of these bases
      together will make a basis for \(\mathbb{R}^n\).
    </p><span class="incontext"><a href="section-spectral-theorem.html#p-519">in-context</a></span>
