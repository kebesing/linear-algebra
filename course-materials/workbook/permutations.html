<!DOCTYPE html>
<html>
<!--*                                    *-->
<!--* Generated from MathBook XML source *-->
<!--*    on 2014-10-05T14:36:33-05:00    *-->
<!--*                                    *-->
<!--*   http://mathbook.pugetsound.edu   *-->
<!--*                                    *-->
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Permutation Matrices</title>
<meta name="Keywords" content="Authored in MathBook XML">
<meta name="viewport" content="width=device-width,  initial-scale=1.0, user-scalable=0, minimum-scale=1.0, maximum-scale=1.0">
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [['\\(','\\)']]
    },
    TeX: {
        extensions: ["AMSmath.js", "AMSsymbols.js", "extpfeil.js", "autobold.js"],
        equationNumbers: { autoNumber: "none",
                           useLabelIds: true,
                           formatID: function (n) {return String(n).replace(/[:'"<>&]/g,"")},
                         },
        TagSide: "right",
        TagIndent: ".8em",
    },
    "HTML-CSS": {
        scale: 88,
    },
});
</script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML-full"></script><script src="http://sagecell.sagemath.org/static/jquery.min.js"></script><script src="http://sagecell.sagemath.org/embedded_sagecell.js"></script><script>
$(function () {
    // Make *any* div with class 'sage-compute' an executable Sage cell
    sagecell.makeSagecell({inputLocation: 'div.sage-compute',
                           linked: true,
                           evalButtonText: 'Evaluate'});
});
$(function () {
    // Make *any* div with class 'sage-display' a visible, uneditable Sage cell
    sagecell.makeSagecell({inputLocation: 'div.sage-display',
                           editor: 'codemirror-readonly',
                           hide: ['evalButton', 'editorToggle', 'language']});
});
    </script><script type="text/javascript" src="http://code.jquery.com/jquery-latest.min.js"></script><link href="http://aimath.org/knowlstyle.css" rel="stylesheet" type="text/css">
<script type="text/javascript" src="http://aimath.org/knowl.js"></script><script src="http://aimath.org/mathbook/js/lib/jquery.sticky.js"></script><script src="http://aimath.org/mathbook/js/lib/jquery.espy.min.js"></script><script src="http://aimath.org/mathbook/js/Mathbook.js"></script><link href="http://fonts.googleapis.com/css?family=Open+Sans:400,400italic,600,600italic%7CSource+Code+Pro:400" rel="stylesheet" type="text/css">
<link href="http://aimath.org/mathbook/stylesheets/mathbook-3.css" rel="stylesheet" type="text/css">
<link href="http://aimath.org/mathbook/mathbook-add-on.css" rel="stylesheet" type="text/css">
</head>
<body class="mathbook-book has-toc has-sidebar-left">
<div style="display:none;">\(
    
    \newcommand{\augmatrix}[2]{\left(\begin{array}{@{}#1 |c@{}} #2 \end{array}\right)}
  \)</div>
<header id="masthead"><div class="banner"><div class="container">
<a id="logo-link" href=""></a><div class="title-container">
<h1 class="heading"><span class="title">Math 2500: Linear Algebra</span></h1>
<p class="byline"></p>
</div>
</div></div>
<nav id="primary-navbar"><div class="container">
<div class="navbar-top-buttons">
<button class="sidebar-left-toggle-button button active">Contents</button><div class="tree-nav toolbar toolbar-divisor-3">
<a class="previous-button toolbar-item button" href="lu-decomposition.html">Previous</a><a class="up-button button toolbar-item" href="chapter-2.html">Up</a><a class="next-button button toolbar-item" href="lin-eq-gf2.html">Next</a>
</div>
<button class="sidebar-right-toggle-button button active">Annotations</button>
</div>
<div class="navbar-bottom-buttons toolbar toolbar-divisor-4">
<button class="sidebar-left-toggle-button button toolbar-item active">Contents</button><a class="previous-button toolbar-item button" href="lu-decomposition.html">Previous</a><a class="up-button button toolbar-item" href="chapter-2.html">Up</a><a class="next-button button toolbar-item" href="lin-eq-gf2.html">Next</a>
</div>
</div></nav></header><div class="page">
<aside id="sidebar-left" class="sidebar"><div class="sidebar-content">
<nav id="toc"><h2 class="link"><a href="index.html"><span class="title">Front Matter</span></a></h2>
<ul>
<li><a href="preface-1.html">Preface</a></li>
<li><a href="acknowledgement-1.html">Acknowledgements</a></li>
</ul>
<h2 class="link"><a href="chapter-basic-objects.html"><span class="codenumber">1</span><span class="title">Vectors, the Dot Product, and Matrices</span></a></h2>
<ul>
<li><a href="vectors.html">Vectors</a></li>
<li><a href="dot-product.html">The Dot Product</a></li>
<li><a href="matrices.html">Matrices</a></li>
<li><a href="start-sage.html">Getting Started with Sage</a></li>
<li><a href="basic-objects-going-further.html">Going Further with the Basic Objects</a></li>
</ul>
<h2 class="link active"><a href="chapter-2.html"><span class="codenumber">2</span><span class="title">Linear Equations</span></a></h2>
<ul>
<li><a href="three-pictures.html">Three Geometric Models</a></li>
<li><a href="elimination.html">Solving Systems</a></li>
<li><a href="matrix-elimination.html">Elimination using Matrices</a></li>
<li><a href="lin-eq-going-further-1.html">Going Further with Elimination</a></li>
<li><a href="matrix-algebra.html">Matrix Algebra</a></li>
<li><a href="inverse.html">Matrix Inverses</a></li>
<li><a href="lu-decomposition.html">The \(LU\) Decomposition</a></li>
<li><a href="permutations.html" class="active">Permutation Matrices</a></li>
<li><a href="lin-eq-gf2.html">Matrix Algebra: Going Further</a></li>
</ul>
<h2 class="link"><a href="chapter-subspaces.html"><span class="codenumber">3</span><span class="title">Vector Spaces and Subspaces</span></a></h2>
<ul>
<li><a href="vector-spaces.html">Subspaces of \(\mathbb{R}^n\)</a></li>
<li><a href="nullspace.html">The Nullspace</a></li>
<li><a href="rank.html">Rank and the RREF</a></li>
<li><a href="complete-solution.html">Solving a System</a></li>
<li><a href="soln-gf.html">Going Further with Solving Systems</a></li>
<li><a href="basis.html">Bases</a></li>
<li><a href="four-subspaces.html">The Four Subspaces</a></li>
<li><a href="ftla-gf.xml.html">Going Further with the Fundamental Theorem</a></li>
</ul>
<h2 class="link"><a href="chapter-orthogonality.html"><span class="codenumber">4</span><span class="title">Orthogonality</span></a></h2>
<ul></ul>
<h2 class="link"><a href="chapter-determinants.html"><span class="codenumber">5</span><span class="title">Determinants</span></a></h2>
<ul></ul>
<h2 class="link"><a href="chapter-eigendata-and-svd.html"><span class="codenumber">6</span><span class="title">Eigendata and the Singular Value decomposition</span></a></h2>
<ul></ul></nav><div class="extras"><nav><a class="feedback-link" href="https://docs.google.com/forms/d/1ru8ipyTKm2QsWRYILXilnle9dC7rr6j8a22hLdvCGKU/viewform?usp=send_form">Leave Feedback</a><a class="mathbook-link" href="http://mathbook.pugetsound.edu">Authored in MathBookÂ XML</a></nav></div>
</div></aside><main class="main"><div id="content" class="mathbook-content"><section class="section" id="permutations"><header><h1 class="heading">
<span class="type">Section</span><span class="codenumber">2.8</span><span class="title">Permutation Matrices</span>
</h1></header><section class="subsection" id="subsection-51"><header><h1 class="heading">
<span class="type">Subsection</span><span class="codenumber"></span><span class="title">The Assignment</span>
</h1></header><ul>
<li>Read section 2.7 of <em>Strang</em>
</li>
<li>Read the following and complete the exercises below.</li>
</ul></section><section class="subsection" id="subsection-52"><header><h1 class="heading">
<span class="type">Subsection</span><span class="codenumber"></span><span class="title">Learning Goals</span>
</h1></header><p>Before class, a student should be able to:</p>
<ul>
<li>
        Compute the transpose of a matrix.
      </li>
<li>
        Correctly perform calculations where the transpose interacts with the
        operations of matrix sum, matrix product, and matrix inverse.
      </li>
<li>
        Compute inner and outer products using the transpose.
      </li>
<li>
        Decide if a matrix is symmetric or not.
      </li>
<li>
        Recognize permutation matrices, and design permutation matrices which
        correspond to given row swaps.
      </li>
</ul>
<p>
      Some time after class, a student should be able to:
    </p>
<ul>
<li>
        Find the \(LDL^T\) decomposition for symmetric matrices.
      </li>
<li>
        Explain how the necessity of permuting rows during Gaussian elimination
        leads to the decomposition \(PA = LU\).
      </li>
<li>
        Explain why \(P^T = P^{-1}\) for permutation matrices.
      </li>
</ul></section><section class="subsection" id="subsection-53"><header><h1 class="heading">
<span class="type">Subsection</span><span class="codenumber"></span><span class="title">Discussion: Transposes, Symmetric Matrices, and Permutations</span>
</h1></header><p>
      An important operation on matrices we have yet to encounter is called the
      <em class="terminology">transpose</em>. If \(A\) is an \(m\times n\) matrix, the
      transpose \(A^T\) of
      \(A\) is made by changing the roles of the rows and the columns. The result
      \(A^T\) will be an \(n \times m\) matrix, because of this switch.
    </p>
<p>
      For now, the transpose will feel like some random thing, but its primary
      importance comes from its connection with the dot product. If we think of
      column vectors \(u\) and \(v\) of size \(n\) as if they are \(n \times 1\)
      matrices, then the dot product \(u \cdot v\) can be computed with a nice
      combination of matrix multiplication and the transpose:
      \[
      u \cdot v = u^T v .
      \]
      On the right, this is matrix multiplication! That makes sense because
      \(u^T\) is \(1 \times n\) and \(v\) is \(n \times 1\). This
      means that the result
      is a \(1\times 1\) matrix, i.e. a number.
    </p>
<p>
      Since the dot product contains all of the geometry of Euclidean space in
      it, the transpose becomes an important operation. I know that sounds weird,
      but the dot product contains all of the information we need to measure
      lengths and angles, so basically all of the <em>metric</em> information in
      Euclidean geometry is there.
    </p>
<section class="subsubsection" id="subsubsection-29"><header><h1 class="heading">
<span class="type">Subsubsection</span><span class="codenumber"></span><span class="title">Algebraic results about the transpose</span>
</h1></header><p>
        There are some key results about the way the transpose interacts with
        other matrix operations, each of these can be checked with some tedious
        computation:
      </p>
<ul>
<li>
          If \(A\) and \(B\) are matrices of the same shape, then
          \((A+B)^T = A^T + B^T\).
        </li>
<li>
          If \(A\) and \(B\) are of sizes so that \(AB\) is defined,
          then \((AB)^T = B^T A^T\).
        </li>
<li>
          If \(A\) is an invertible matrix, with inverse \(A^{-1}\),
          then \(A^T\) is also invertible and it has inverse
          \(\left(A^T\right)^{-1} = \left(A^{-1}\right)^T \).
        </li>
</ul></section><section class="subsubsection" id="subsubsection-30"><header><h1 class="heading">
<span class="type">Subsubsection</span><span class="codenumber"></span><span class="title">Symmetric Matrices</span>
</h1></header><p>
        A matrix \(A\) is called <em>symmetric</em> when \(A^T = A\). These
        pop up in lots of interesting places in linear algebra. A neat result
        is that a symmetric matrix has a symmetric looking \(LDU\) decomposition:
        \[
        \text{if } A^T=A\text{, then } A = LDL^T .
        \]
        That is, in the LDU decomposition, \(U = L^T\).
      </p>
<p>
        There are several ways to get symmetric matrices. For example, if
        \(A\) is any matrix, the new matrix \(B = A^T A\) will be symmetric.
        (Check this.) Also, the matrix \(S = A^T + A\) will be symmetric.
      </p></section><section class="subsubsection" id="subsubsection-31"><header><h1 class="heading">
<span class="type">Subsubsection</span><span class="codenumber"></span><span class="title">Permutation Matrices and Pivoting strategies in Gauss-Jordan Elimination</span>
</h1></header><p>
        It is sometimes the case that Gauss-Jordan elimination requires a row
        swap. As we have seen, the operation of swapping a row can be achieved
        by left multiplying by a matrix of a special type. If we take a bunch of
        those and multiply them together, we still get a matrix which is in a
        special class: <em>the permutation matrices</em>.
      </p>
<p>
        A permutation matrix is square matrix having a single \(1\) in each column
        and in each row. A helpful property of permutation matrices is that they
        are invertible, and their inverses are the same as their transposes:
        \[
        P^{-1} = P^T .
        \]
      </p>
<p>
        Gauss-Jordan elimination is easy enough to understand, now. It is time
        to let go of performing all those arithmetic operations by hand. So,
        permutation matrices become important for a different reason! Even if
        Gauss-Jordan elimination can be done without a row swap, it may be
        numerically better for a computer to swap out for a larger number as a
        pivot, so a row swap is used anyway. This partial pivoting strategy is
        encapsulated in most computer algebra algorithms in some way, and is
        part of the computation involved in computing a PLU decomposition.
        Strang has a decent discussion of the choices, below we will
        discuss how Sage handles this.
      </p></section></section><section class="subsection" id="subsection-54"><header><h1 class="heading">
<span class="type">Subsection</span><span class="codenumber"></span><span class="title">Sage and Transposes, Symmetry, Permutations, and Pivots</span>
</h1></header><p>
      There is a lot going on in this little section. At first glance, it is a
      bit intimidating. But we have seen most of the ideas before.
    </p>
<section class="subsubsection" id="subsubsection-32"><header><h1 class="heading">
<span class="type">Subsubsection</span><span class="codenumber"></span><span class="title">The Transpose</span>
</h1></header><p>
        The transpose of a matrix is what you get by switching the roles of rows
        and columns. Sage has a simple method for this.
      </p>
<div class="sage-compute"><script type="text/x-sage">M = MatrixSpace(QQ, 3,3)
A = M([1,2,3,4,5,6,7,8,9]); A
</script></div>
<div class="sage-compute"><script type="text/x-sage">A.transpose()
</script></div>
<p>
        One place that the transpose is useful is in describing the dot product.
        Check this out.
      </p>
<div class="sage-compute"><script type="text/x-sage">u = vector([1,2,3])
v = vector([4,5,6])
u.dot_product(v)
</script></div>
<div class="sage-compute"><script type="text/x-sage">U = u.column(); U # this puts u into a column matrix
</script></div>
<p>
        To be sure, we check what the âparentâ of <tt class="code-inline" style="color: red; font-size: 120%">U</tt> is.
      </p>
<div class="sage-compute"><script type="text/x-sage">U.parent()
</script></div>
<p>
        See! Sage thinks of <tt class="code-inline" style="color: red; font-size: 120%">U</tt> as a matrix with 3 rows and 1 column.
      </p>
<p>
        Now we do the same with <tt class="code-inline" style="color: red; font-size: 120%">v</tt>
      </p>
<div class="sage-compute"><script type="text/x-sage">V = v.column()
V
</script></div>
<p>
        Now the magic.
      </p>
<div class="sage-compute"><script type="text/x-sage">U.transpose()*V
</script></div>
<div class="sage-compute"><script type="text/x-sage">V.transpose()*U
</script></div>
<p>
        That is the dot product, but stuffed into a \(1\times 1\) matrix!
      </p></section><section class="subsubsection" id="subsubsection-33"><header><h1 class="heading">
<span class="type">Subsubsection</span><span class="codenumber"></span><span class="title">Other Properties</span>
</h1></header><p>
        The transpose has other useful properties. Strang lists the big ones,
        including how the transpose interacts with matrix multiplication and
        matrix inverses.
      </p></section><section class="subsubsection" id="subsubsection-34"><header><h1 class="heading">
<span class="type">Subsubsection</span><span class="codenumber"></span><span class="title">Symmetry</span>
</h1></header><p>
        A matrix is called <em class="terminology">symmetric</em> when it is equal to its
        transpose. Sage has some built-in commands for this.
      </p>
<div class="sage-compute"><script type="text/x-sage">B = M([2,1,0,1,1,0,0,0,1])
B
</script></div>
<div class="sage-compute"><script type="text/x-sage">B.transpose()
</script></div>
<div class="sage-compute"><script type="text/x-sage">B.is_symmetric()
</script></div>
<div class="sage-compute"><script type="text/x-sage">C = M([1,0,1,1,1,1,0,0,0]); C
</script></div>
<div class="sage-compute"><script type="text/x-sage">C.is_symmetric()
</script></div>
<p>
        Strang notes a really neat property of symmetric matrices. Their
        \(LDU\) decompostions are nicer than average.
      </p>
<div class="sage-compute"><script type="text/x-sage">P, L, U = B.LU(pivot='nonzero')
</script></div>
<div class="sage-compute"><script type="text/x-sage">P # here, things are good and no row swaps are needed
</script></div>
<div class="sage-compute"><script type="text/x-sage">L
</script></div>
<div class="sage-compute"><script type="text/x-sage">U
</script></div>
<div class="sage-compute"><script type="text/x-sage">D = M([2,0,0,0,1/2,0,0,0,1])
Uprime = D.inverse()*U
Uprime
</script></div>
<div class="sage-compute"><script type="text/x-sage">B == L*D*Uprime
</script></div>
<div class="sage-compute"><script type="text/x-sage">L.transpose() # this is the neat part
</script></div></section><section class="subsubsection" id="subsubsection-35"><header><h1 class="heading">
<span class="type">Subsubsection</span><span class="codenumber"></span><span class="title">Permutations and Pivots</span>
</h1></header><p>
        We have seen that elimination sometimes requires us to perform a row
        operation of swapping the position of two rows to put a pivot in a good
        place. At first, we want to do this to avoid a zero. But for computational
        reasons, a machine really likes to have a <em>big</em> number as a pivot.
        So software often uses rows swaps even when not strictly needed.
      </p>
<p>
        If all we care about is finding the reduced row echelon form (rref),
        then this won't worry us. You do whatever operations you want, and the
        rref is always the same thing. But if we want to keep track with matrices,
        things get a little complicated.
      </p>
<p>
        Here is the important stuff to remember:
        <ol>
<li>A row swap is performed by a permutation matrix. A permutation matrix
            is a matrix with exactly one \(1\) in each column and in each row.
            These matrices have the important property that their transposes and
            their inverses are equal. That is, if \(P\) is a permutation matrix,
            then \(P^T\) is equal to \(P^{-1}\). (Not every matrix with
            this extra property is a permutation matrix. Be careful.)
          </li>
<li>
            It is possible to figure out what all of the row swaps should be, and
            then rearrange all of the amtrices in an LU decomposition routine.
            If you do it correctly, you get:
            \[
              P'A = LU
            \]
            or
            \[
              A = PLU
            \]
            where \(P'\) and \(P\) are permutation matrices.
          </li>
</ol>
      </p>
<p>
        Note: Strang prefers to write things as \(P'A = LU\), but Sage writes
        \(A = PLU\). Fortunately, there is a simple relationship here. Strang's
        \(P'\) is the transpose (and hence the inverse!) of Sage's \(P\).
      </p>
<p>
        If you haven't figured it out by now, I think that row reduction by hand
        is really for chumps. Sage (or whatever computational tool you use) makes
        it waaaaaaaaay easier.
      </p>
<div class="sage-compute"><script type="text/x-sage"># using 'partial pivoting' where we get "big pivots"
P, L, U = A.LU()
x = '{0!r}\n\n{1!r}\n\n{2!r}'.format(P,L,U)
print x # fancy python tricks for readable display
</script></div>
<div class="sage-compute"><script type="text/x-sage">P*L*U
</script></div>
<div class="sage-compute"><script type="text/x-sage">A == P*L*U
</script></div>
<div class="sage-compute"><script type="text/x-sage">P.transpose()*A == L*U
</script></div>
<div class="sage-compute"><script type="text/x-sage">P.transpose()*A
</script></div></section></section><section class="subsection" id="subsection-55"><header><h1 class="heading">
<span class="type">Subsection</span><span class="codenumber"></span><span class="title">Exercises</span>
</h1></header><p>
      Keep this in mind. The computations are simple, but tedious.
      Perhaps you want to use an appropriate tool.
    </p>
<article class="example-like" id="task-76"><h5 class="heading">
<span class="type">Task</span><span class="codenumber">46</span><span class="title"></span>
</h5>
        Find an example of a matrix \(A\) such that \(A^T A = 0\),
        but \(A \neq 0\).
      </article><article class="example-like" id="task-77"><h5 class="heading">
<span class="type">Task</span><span class="codenumber">47</span><span class="title"></span>
</h5>
        These are true or false questions. If the statement is true, explain why
        you know it is true. If the statement is false, give an example that
        shows it is false.
        <ol>
<li>
            The block matrix \(\left( \begin{smallmatrix} A &amp; 0 \\
            0 &amp; A \end{smallmatrix}\right)\) is automatically symmetric.
          </li>
<li>
            If \(A\) and \(B\) are symmetric, then their product \(AB\)
            is symmetric.
          </li>
<li>
            If \(A\) is not symmetric, then \(A^{-1}\) is not symmetric.
          </li>
</ol></article><article class="example-like" id="task-78"><h5 class="heading">
<span class="type">Task</span><span class="codenumber">48</span><span class="title"></span>
</h5>
        If \(P_1\) and \(P_2\) are permuation matrices, then so is
        \(P_1P_2\). Give examples with \(P_1P_2 \neq P_2P_1\) and
        \(P_3P_4 = P_4P_3\).
      </article><article class="example-like" id="task-79"><h5 class="heading">
<span class="type">Task</span><span class="codenumber">49</span><span class="title"></span>
</h5>
        Explain the following phenomena in terms of row operations.
        <ol>
<li>
            For any permutation matrix \(P\), it is the case that
            \(P^T P = I\).
          </li>
<li>
            All row exchange matrices are symmetric: \(P^T = P\).
            (other permutation matrices may or may not be symmetric.)
          </li>
<li>
            If \(P\) is a row exchange matrix, then \(P^2 = I\).
          </li>
</ol></article><article class="example-like" id="task-80"><h5 class="heading">
<span class="type">Task</span><span class="codenumber">50</span><span class="title"></span>
</h5>
        For each of the following, find an example of a \(2\times 2\)
        symmetric matrix with the given property:
        <ol>
<li> \(A\) is not invertible.</li>
<li> \(A\) is invertible but cannot be factored into \(LU\).</li>
<li>
            \(A\) can be factored into \(LDL^T\), but not into
            \(LL^T\) because \(D\) has negative entries.
          </li>
</ol></article><article class="example-like" id="task-81"><h5 class="heading">
<span class="type">Task</span><span class="codenumber">51</span><span class="title"></span>
</h5>
<p>
          This is a new factorization of \(A\) into <em>triangular
          times symmetric</em>:
        </p>
<p>
          Start with \(A = LDU\). Then \(A = B S\),
          where \(B = L\left(U^T\right)^{-1}\) and \(S = U^T D U\).
        </p>
<p>
          Explain why this choice of \(B\) is lower triangular with
          \(1\)'s on the diagonal. Expain why \(S\) is symmetric.
        </p></article></section></section></div></main>
</div>
</body>
</html>
