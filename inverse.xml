<?xml version="1.0" encoding="UTF-8" ?>

<!-- This file is part of the workbook                        -->
<!--                                                          -->
<!--    Math 2500: Linear Algebra                             -->
<!--                                                          -->
<!-- Copyright (C) 2014  Theron J. Hitchman                   -->
<!-- See the file COPYING for copying conditions.             -->

<section xml:id="inverse">
  <title>Matrix Inverses</title>

  <subsection>
    <title>The Assignment</title>
    <ul>
      <li>Read section 2.5 of <em>Strang</em>.</li>
      <li>
        Watch a video from the YouTube series <em>Essence of Linear Algebra</em>
        by user <em>3Blue1Brown</em>.
      </li>
      <li>Read the following and complete the exercises below.</li>
    </ul>
  </subsection>

  <subsection>
    <title>Learning Goals</title>
    <p>
      Before class, a student should be able to:
    </p>
    <ul>
      <li>State the definition of <term>invertible</term> matrix.</li>
      <li>Solve an equation <m>Ax = b</m> using the inverse of <m>A</m>
        if it exists.
      </li>
      <li>State how inverses and multiplication interact.</li>
      <li>Use Gauss-Jordan elimination to compute the inverse of a matrix.</li>
      <li>State a test for invertibility of square matrices using pivots.</li>
    </ul>
    <p>
      Some time after class, a student should be able to:
    </p>
    <ul>
      <li>Describe the connection between Gauss-Jordan elimination and solving
        <m>n</m> different systems of equations.
      </li>
      <li>Describe the connection between Gauss-Jordan elimination, computing
        matrix inverses, and the process of elimination by matrix multiplication.
      </li>
      <li>State the definition of the determinant of a square matrix.</li>
      <li>State the connection between the determinant of a square matrix and
        invertibility.</li>
      <li>State the distinction between a matrix being <term>invertible</term>
        and a matrix being <term>singular</term>.
      </li>
    </ul>



  </subsection>

  <subsection>
    <title>Discussion</title>
    <subsubsection>
      <title>Matrix Inverses</title>
      <p>
        The main point of this section is to start focusing on the first big
        problem in linear algebra. How can you tell, in advance, that a system
        of <m>n</m> equations in <m>n</m> unknowns will have a solution?
      </p>
      <p>
        Of course, like all things we have been studying, this will have several
        different faces, all of which are equivalent. The one front and center
        right now is this: When does an <m>n \times n</m> square matrix have an inverse?
      </p>
    </subsubsection>

    <subsubsection>
      <title>Finding an Inverse: Gauss-Jordan Elimination</title>
      <p>
        There is an effective method for finding the inverse, and it is
        Gauss-Jordan elimination. (This is sometimes just called
        <em>Gaussian elimination</em>.) Essentially, you wish to solve <m>n</m>
        different systems <m>Ax= b</m> of size <m>n\times n</m> all at the same
        time, with specially chosen right hand sides.
      </p>
      <p>
        The process is an algorithm, so it is very specific. If you do this some
        other way, you aren't doing Gauss-Jordan Elimination. The name is applied
        to the process.
      </p>
      <p>
        <em>Gauss-Jordan Elimination</em>
      </p>
      <ul>
        <li>
          <em>Augment:</em> Tack on a copy of the identity matrix of the same
          size to the right hand side of your matrix. It should now look like
          <m>(A \mid I)</m>.
        </li>
        <li>
          <em>Forward Pass:</em> This is a nested procedure:
          <ul>
            <li>
              <em>preparation:</em> If necessary, use a row swap to make a
              non-zero entry in the upper left entry.
            </li>
            <li>
              <em>make zeros:</em> The upper left entry is our first pivot. Use
              the operation of adding a multiple of the first row to the other
              rows to kill the entries below this first pivot.
            </li>
            <li>
              <em>step down:</em> Step down to the second row and repeat the
              above, but ignoring rows and columns above and to the left. Repeat
              as necessary till you run out of rows.
            </li>
          </ul>
          If at any point in the process you get a row consisting of only zeros,
          perform a row switch to suffle it to the bottom. When the forward
          pass is complete, you should have an upper triangular matrix.
        </li>
        <li>
          <em>Backward Pass:</em> This is also nested, like the forward pass,
          except that instead of working down and to the right, you begin at
          the lower right with the last pivot and work up and to the left.
          When complete, the matrix should have at most one non-zero entry in
          each row. This entry will be a pivot.
        </li>
        <li>
          <em>Rescale:</em> rescale rows to make the pivots into <m>1</m>'s.
        </li>
      </ul>

      <p>
        At the end of the whole process, you should have something that looks
        like this: <m>(I \mid B)</m>. The wonderful part: <m>B</m> is the
        inverse of <m>A</m>. Well, almost. The process can fail! If along the
        line you find that the left hand block of your big augmented matrix
        doesn't have <m>n</m> pivots in it, then your matrix was not invertible.
      </p>
      <p>
        What you have computed in the left hand block with the Gauss-Jordan
        elimination is the <em>reduced row-echelon form</em> of your original matrix.
      </p>
    </subsubsection>
    <subsubsection>
      <title>The Big Theorem: invertibility, singularity, and the determinant</title>
      <p>
        What is the key?
      </p>

      <theorem>
        <statement>
          An <m>n\times n</m> matrix <m>A</m> is invertible exactly when it has
          <m>n</m> pivots. Equivalently, its reduced row-echelon form has <m>n</m>
          non-zero entries down the diagonal. The inverse will be computed by
          Gauss-Jordan elimination.
        </statement>
      </theorem>
      <p>
        This is huge. The algorithm is not difficult, and it answers an
        important question exactly.
      </p>
      <p>
        Note that we said a square matrix was <em>singular</em> when it did not
        have enough pivots. So what the above says is that a matrix is invertible
        if and only if it is non-singular.
      </p>
    </subsubsection>
    <subsubsection>
      <title>A simple test</title>
      <p>
        We can use the above to make a simple numerical test of when a matrix is
        invertible. First do the forward pass of elimination to obtain an upper
        triangular matrix. Take the product of the diagonal entries. This will
        be zero if and only if one of the diagonal entries is zero, which will
        only happen if there are fewer than <m>n</m> pivots. This product is then
        helpful enough to test for invertibility, and so it deserves its own
        name: the <term>determinant</term>. We shall learn more about this quantity later.
      </p>
    </subsubsection>
  </subsection>

  <subsection>
    <title>SageMath and Gauss-Jordan Elimination</title>
    <p>
      We have already seen that SageMath has commands for constructing matrices and
      performing row operations. Those are the operations used to perform
      Gauss-Jordan Elimination. But there are several interesting and useful
      commands in this neighborhood we have not yet discussed.
    </p>
    <p>
      Let us construct my favorite matrix so we have something to play with.
    </p>
    <sage>
      <input>
        A = matrix(QQ, 2,2, [2,1,1,1])
      </input>
    </sage>
    <p>
      We can use the <c>.is_invertible()</c> method to check that <c>A</c> is
      invertible. In general, this method returns <c>True</c> or <c>False</c>.
    </p>
    <sage>
      <input>
        A.is_invertible()
      </input>
      <output>
        True
      </output>
    </sage>
    <p>
      And we can get SageMath to just compute the inverse for us.
    </p>
    <sage>
      <input>
        A.inverse()
      </input>
      <output>
        [ 1 -1]
        [-1  2]
      </output>
    </sage>
    <p>
      Just so we can see what happens if the matrix is not invertible, we try
      another matrix.
    </p>
    <sage>
      <input>
        B = matrix(QQ, 2,2, [0,1,0,0])
        B.is_invertible()
      </input>
      <output>
        False
      </output>
    </sage>
    <sage>
      <input>
        B.inverse()
      </input>
      <output>
        Error in lines 1-1
        ...
        ZeroDivisionError: input matrix must be nonsingular
      </output>
    </sage>
    <p>
      We can also ask SageMath to compute determinants with the <c>.determinant()</c>
      method.
    </p>
    <sage>
      <input>
        A.determinant(), B.determinant()
      </input>
      <output>
        (1,0)
      </output>
    </sage>
    <p>
      SageMath is also capable of computing the reduced row echelon form
      (the <q>rref</q>) of a matrix with the appropriately named <c>.rref()</c>
      method.
    </p>
    <sage>
      <input>A.rref()</input>
      <output>
        [1 0]
        [0 1]
      </output>
    </sage>
    <p>
      The method <c>.rref()</c> does not change the matrix <c>A</c>. There is
      another command which will work the same way for our purposes,
      <c>.echelon_form()</c>.
    </p>
    <sage>
      <input>A.echelon_form()</input>
      <output>
        [1 0]
        [0 1]
      </output>
    </sage>
    <p>
      There is a related command which <em>will find the rref and then update the
      matrix</em>. It is called <c>.echelonize()</c>.
      Because I don't really want to mess with <c>A</c>, we will
      make a copy first.
    </p>
    <sage>
      <input>
        C = copy(A) # fancy Python trick! (not so fancy)
        C.echelonize()
      </input>
    </sage>
    <p>
      Now we ask sage to print those out for us.
    </p>
    <sage>
      <input>
        print A
        print '\n'
        print C
      </input>
      <output>
        [2 1]
        [1 1]

        [1 0]
        [0 1]
      </output>
    </sage>

    <p>
      Now, we can be just a bit more hands-on with Gauss-Jordan elimination
      if we do it this way. We will combine commands we have used before to
      do this.
    </p>
    <sage>
      <input>
        M = MatrixSpace(QQ, 2,2)
        M(1) # this is the 2x2 identity
      </input>
      <output>
        [1 0]
        [0 1]
      </output>
    </sage>
    <p>
      Now we do the algorithm.
    </p>
    <sage>
      <input>
        D = A.augment(M(1))
        D.rref()
      </input>
      <output>
        [ 1  0  1 -1]
        [ 0  1 -1  2]
      </output>
    </sage>
    <p>
      That was good. But we only need the right-hand submatrix. We can get SageMath
      to report just that!
    </p>
    <sage>
      <input>E = D.rref().matrix_from_columns([2,3]); E</input>
      <output>
        [ 1 -1]
        [-1  2]
      </output>
    </sage>
    <p>
      It is often convenient to chain methods together like this. Then you can
      read what happens from left to right.
    </p>
  </subsection>

  <subsection>
    <title>Exercises</title>
    <p>
      Keep this in mind. The computations are simple, but tedious.
      Perhaps you want to use an appropriate tool.
    </p>

    <task>
      <statement>
        Use Gauss-Jordan elimination to find the inverse of the matrix <m>A</m> below.
        <me>
        A = \begin{pmatrix} 3 &amp; 17 \\ 1 &amp; 6 \end{pmatrix}
        </me>
        Be sure to clearly write down the operations you use and the matrices
        which perform the operations by left multiplication.
      </statement>
    </task>

    <task>
      <statement>
        Use Gauss-Jordan elimination to find the inverse of the matrix <m>X</m> below.
        <me>
        X = \begin{pmatrix} a &amp; b \\ c &amp; d \end{pmatrix}
        </me>
        Be sure to clearly write down the operations you use and the matrices
        which perform the operations by left multiplication.
      </statement>
    </task>

    <task>
      <statement>
        Use Gauss-Jordan elimination to find the inverse of the matrix <m>B</m> below.
        <me>
        B = \begin{pmatrix} 3 &amp; 4 &amp; -1\\ 1 &amp; 6 &amp; 1 \\
        0 &amp; 3 &amp; -1 \end{pmatrix}
        </me>
        Be sure to clearly write down the operations you use and the matrices
        which perform the operations by left multiplication.
      </statement>
    </task>

    <task>
      <statement>
        Use Gauss-Jordan elimination to find the inverse of the matrix <m>B</m> below.
        <me>
        B = \begin{pmatrix}
        0 &amp; 3 &amp; 4 &amp; -1\\
        0 &amp; 1 &amp; 6 &amp; 1 \\
        2 &amp; 0 &amp; 3 &amp; -1 \\
        5 &amp; -1 &amp; 1 &amp; 3
        \end{pmatrix}
        </me>
        Be sure to clearly write down the operations you use and the matrices
        which perform the operations by left multiplication.
      </statement>
    </task>



    <task>
      <statement>
        Use Gauss-Jordan elimination to find the inverse of the matrix <m>D</m> below.
        <me>
        D = \begin{pmatrix}
        3 &amp; 17 &amp; -1 &amp; 3 &amp; 1 \\ 1 &amp; 6 &amp; -2 &amp; 1 &amp; 1 \\
        2 &amp; 2 &amp; 1 &amp; -5 &amp; 1 \\ 0 &amp; 0 &amp; 3 &amp; 1 &amp; -3 \\
        -2 &amp; 3 &amp; 4 &amp; 1 &amp; 1
        \end{pmatrix}
        </me>
      </statement>
    </task>

    <task>
      <statement>
        Suppose that for the matrix <m>D</m> in the last exercise we imagine solving the matrix
        equation <m>Dx = b</m> for some vector <m>b</m> of the appropriate size. What might one mean
        by the row picture in this case? What might the column picture mean?
      </statement>
    </task>



    <task>
      <statement>
        Design a <m>6 \times 6</m> matrix which has the following properties:
        <ul>
          <li> no entry equal to zero</li>
          <li> the reduced row echelon form should have exactly 5 pivots</li>
          <li> the 5 pivots should be different numbers</li>
          <li> no pair of rows should be scalar multiples of one another</li>
        </ul>
        Is your matrix invertible? How do you know? Does Sage say it is invertible?
      </statement>
    </task>


  </subsection>


</section>
