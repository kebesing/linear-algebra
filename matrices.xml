<?xml version="1.0" encoding="UTF-8" ?>

<!-- This file is part of the workbook                        -->
<!--                                                          -->
<!--    Math 2500: Linear Algebra                             -->
<!--                                                          -->
<!-- Copyright (C) 2014  Theron J. Hitchman                   -->
<!-- See the file COPYING for copying conditions.             -->

<section xml:id="matrices">
  <title>Matrices</title>

  <subsection>
    <title>The Assignment</title>

    <ul>
      <li>Read <em>Strang</em> section 1.3 (pages 22-27).</li>
      <li>Read the following and complete the exercises below.</li>
    </ul>

  </subsection>


  <subsection>
    <title>Learning Goals</title>
    <p>Before class starts, a student should be able to:
      <ul>
        <li>multiply a matrix times a vector
          <ul>
            <li>as a linear combination of columns</li>
            <li>as a set of dot products, row times column</li>
          </ul>
        </li>
        <li>translate back and forth between our three representations
          <ul>
            <li>a system of linear equations,</li>
            <li>a linear combination of vectors equation, and</li>
            <li>a matrix equation <m>Ax=b</m>.</li>
          </ul>
        </li>
        <li>Correctly identify the rows and columns of a matrix</li>
        <li>describe what is meant by a lower triangular matrix</li>
      </ul>
    At some point, as student should be comfortable with these concepts, which
    get a very brief informal introduction in this section:
    <ul>
      <li>linear dependence and linear independence</li>
      <li>the inverse of a matrix</li>
    </ul>
  </p>
  </subsection>

  <subsection>
    <title>Discussion</title>

    <p>
      A <term>matrix</term> is a two-dimensional array of numbers like this:<me>
        A = \begin{pmatrix} 2 &amp; 1 \\ 1 &amp; 1 \end{pmatrix}.
      </me>
      Sometimes it helps to think of a matrix as a collection of its <term>rows</term>
      which are read across:<me>
        M = \begin{pmatrix} \longrightarrow \\ \longrightarrow \end{pmatrix}
      </me>
      and sometimes it helps to think of a matrix as a collection of its
      <term>columns</term> which are read down:<me>
        M = \begin{pmatrix} \downarrow &amp; \downarrow \end{pmatrix}.
      </me>
    </p>
    <p>
      It is often more clear to describe a matrix by giving the sizes of its
      rows and columns. An <m>m</m> by <m>n</m> matrix is one having <m>m</m>
      rows and <m>n</m> columns. It is really easy to get these reversed, so be
      careful. For example, this is a <m>2\times 3</m> matrix, because it has
      two rows and three columns:<me>
        B = \begin{pmatrix} 1 &amp; 1 &amp; 2 \\ 3 &amp; 5 &amp; 8 \end{pmatrix}
      </me>
      A matrix is called a <term>square</term> matrix when the number of rows and
      the number of columns is equal. The matrix <m>A</m> that I wrote down
      above is square because it is a <m>2\times 2</m> matrix.
    </p>

    <subsubsection>
      <title>Multiplying Matrices and Vectors</title>

      <p>
        It is possible to multiply a matrix by a vector like this:<me>
          \begin{pmatrix} 1 &amp; 1 &amp; 2 \\ 3 &amp; 5 &amp; 8 \end{pmatrix}
          \begin{pmatrix} 13 \\ 21 \\ 34 \end{pmatrix} =
          \begin{pmatrix} 102 \\ 416 \end{pmatrix}
        </me>
        For this to work, it is absolutely crucial that the sizes match up
        properly. If the matrix is <m>m</m> by <m>n</m>, then the vector must have
        size <m>n</m>. In the above example <m>m = 2</m> and <m>n=3</m>.
      </p>
      <p>
        Later, we shall see that the word "multiplication" is not really the
        best choice here. It is better to think of the matrix as "acting on"
        the vector and turning it into a new vector. For now, the word
        multiplication will serve.
      </p>
      <p>
        How exactly does one define this matrix--vector multiplication?
      </p>

      <paragraphs>
        <title>Linear Combination of Columns Approach</title>
        <p>
          The first way to perform the matrix-vector multiplication is to think
          of the vector as holding some coefficients for forming a linear
          combination of the columns of the matrix. In our example, it looks
          like this:<me>
            \begin{pmatrix} 1 &amp; 1 &amp; 2 \\ 3 &amp; 5 &amp; 8 \end{pmatrix}
            \begin{pmatrix} 13 \\ 21 \\ 34 \end{pmatrix} =
            13 \begin{pmatrix} 1 \\ 3 \end{pmatrix} + 21 \begin{pmatrix} 1 \\ 5
            \end{pmatrix} + 34 \begin{pmatrix} 2 \\ 8 \end{pmatrix} =
            \begin{pmatrix} 102 \\ 416 \end{pmatrix}
          </me>
        </p>
      </paragraphs>
      <paragraphs>
        <title>Dot Products with the Rows Approach</title>
        <p>
          The second way is to think of the matrix as a bundle of vectors lying
          along the rows of the matrix, and use the dot product. In our example
          above, this means that we consider the vectors<me>
            r_1 = \begin{pmatrix} 1 \\ 1 \\ 2 \end{pmatrix}, \quad
            r_2 = \begin{pmatrix} 3 \\ 5 \\ 8 \end{pmatrix}, \text{ and }
            v = \begin{pmatrix} 13 \\ 21 \\ 34 \end{pmatrix}
          </me>
          (notice I've rewritten the rows as columns) and then perform this
          kind of operation:<me>
            \begin{pmatrix} 1 &amp; 1 &amp; 2 \\ 3 &amp; 5 &amp; 8 \end{pmatrix}
            \begin{pmatrix} 13 \\ 21 \\ 34 \end{pmatrix} = \begin{pmatrix} r_1
            \\ r_2 \end{pmatrix} v =  \begin{pmatrix} r_1 \cdot v \\ r_2 \cdot
            v \end{pmatrix} =
            \begin{pmatrix} 102 \\ 416 \end{pmatrix} .
          </me>
        </p>
      </paragraphs>

      <p>
      Two important remarks:
      <ul>
        <li>
          Note that these operations only make sense if the sizes match up properly.
        </li>
        <li>
          Note that the two versions of the operation give you the same results.
        </li>
      </ul>
      </p>

    </subsubsection>

    <subsubsection>
      <title>Matrix Equations</title>

      <p>
        There are many situations in linear algebra that can be rewritten in
        the form of an equation that looks like this:<me>
          A v = b
        </me>
        where <m>A</m> is a matrix, and <m>v</m> and <m>b</m> are vectors. The
        interesting case is when we know <m>A</m> and <m>b</m>, but we want to
        find the unknown <m>v</m>. We will call this a
        <term>matrix-vector equation</term>.
      </p>

      <p>
        Let's consider the case where you are given some <term>square</term>
        matrix <m>A</m>. Sometimes one can find another matrix <m>B</m> so that
        no matter what vector <m>b</m> is chosen in the matrix-vector equation
        above, the  solution vector takes the form <m>v = Bb</m>. When this
        happens, we say that <m>A</m> is <term>invertible</term> and call <m>B</m>
        the <term>inverse</term> of <m>A</m>. It is common to use the notation
        <m>A^{-1}</m> in place of <m>B</m>. This is a wonderful situation to be
        in! Eventually, we will want to figure out some test for when a given
        matrix is invertible, and find some ways to compute the inverse.
      </p>
    </subsubsection>

    <subsubsection>
      <title>A Note about Vectors</title>

      <p>
        This reading also has a brief introduction to the idea of a set of
        vectors being <term>linearly depedent</term> or <term>linearly independent</term>.
        Strang is coy about the precise definition, so here it is:
      </p>
      <p>
        A set of vectors <m>v_1, v_2, \dots, v_n</m> is called <term>linearly
        depdendent</term> when there is some choice of numbers
        <m>a_1, a_2, \dots, a_n</m> which are not all zero so that the
        linear combination<me>
          a_1 v_1 + a_2 v_2 + \dots + a_n v_n = 0
        </me>
        A set of vectors which is not linearly dependent is called
        <term>linearly independent</term>.
      </p>
      <p>
        This is a little funny the first time you read it. Note that for any
        set of vectors, you can make a linear combination of those vectors
        come out as <m>0</m>. Simply choose all of the coefficients to be
        zero. But that is so easy to do we call it <term>trivial</term>. What the
        definition is asking is that we find a <em>nontrival linear
        combination of the vectors to make zero</em>.
      </p>
      </subsubsection>

  </subsection>

  <subsection>
    <title>Sage and Matrices</title>

    <p>
      Sage has many useful commands for working with linear algebra, and
      given the central role played by matrices in this subject, there are
      lots of things Sage can do with matrices. We'll focus here on just basic
      construction and matrix--vector multiplication.
    </p>

    <subsubsection>
      <title>The matrix construction command</title>

      <p>The command to construct a matrix is pretty straightforward. One types
        <c>matrix(r, c, [list of entries])</c> where <c>r</c> is
        the number of rows and <c>c</c> is the number of columns. The entries
        should be read across the rows starting with the top row.
      </p>
      <sage>
        <input>
          A = matrix(2,3, [1,2,3,5,8,13]); A
        </input>
        <output>
          [ 1  2  3]
          [ 5  8 13]
        </output>
      </sage>
      <p>If you wish, you can structure that list of entries to be a list of lists,
        where each sublist is a row in your matrix.
      </p>
      <sage>
        <input>
          B = matrix(2,3, [[1,2,3], [5,8,13]]); B
        </input>
        <output>
          [ 1  2   3]
          [ 5  8  13]
        </output>
      </sage>
      <p>
        Every once in a while, it might matter to you what kinds of numbers you
        put into the matrix. Sage will let you specify them by putting in an optional
        argument like this: <c>matrix(number type, r, c, [list of entries])</c>
      </p>
      <sage>
        <input>
          C = matrix(ZZ, 2, 2, [2,1,1,1])
          C # the best matrix
        </input>
        <output>
          [2 1]
          [1 1]
        </output>
      </sage>
      <p>
        The notation <c>ZZ</c> means "integers." There are other sets of numbers
        here:
        <ul>
          <li><c>QQ</c> the rational numbers (with exact arithmetic)</li>
          <li><c>RR</c> the real numbers (with computer precision arithmetic)</li>
          <li><c>CC</c> the complex numbers</li>
          <li><c>AA</c> the set of all algebraic numbers, that is, all of the
            numbers that are roots of some polynomial with integer coefficients
          </li>
        </ul>
        You can find out what kind of entries a matrix thinks it has by calling the
        <c>.parent()</c> method on it.
      </p>
      <sage>
        <input>
          A.parent()
          # this should say something about the integers
        </input>
        <output>
          Full MatrixSpace of 2 by 3 dense matrices over Integer Ring
        </output>
      </sage>
      <sage>
        <input>
          D = matrix(QQ, 3,3, [[1,0,1],[2/3, 1, 0],[0,0,9/5]])
          # this should say something about the rationals
          D.parent()
        </input>
        <output>
          [  1   0   1]
          [2/3   1   0]
          [  0   0 9/5]
          Full MatrixSpace of 3 by 3 dense matrices over Rational Field
        </output>
      </sage>
    </subsubsection>
    <subsubsection>
      <title>Building a matrix from rows or columns</title>

      <p>
        It is possible to build a matrix by bundling together a bunch of vectors,
        too. Let's start with an example made using rows.
      </p>
      <sage>
        <input>
          v1 = vector([2,1]); v2= vector([3,4])
          # construct E with rows v1 and v2, then display
          E = matrix([ v1, v2]); E
        </input>
        <output>
          [2 1]
          [3 4]
        </output>
      </sage>
      <p>
        Sage prefers rows. I wish it were the other way, but I am sure there is
        a good reason it prefers rows. If you want to make a matrix whose columns
        are the vectors <c>v1</c> and <c>v2</c>, you can use the
        <c>transpose</c> method. We'll talk more about the operation of transpose
        later, but it basically "switches rows for columns and vice versa."
      </p>
      <sage>
        <input>
          F = matrix([v1,v2]).transpose(); F
        </input>
        <output>
          [2 3]
          [1 4]
        </output>
      </sage>
    </subsubsection>

    <subsubsection>
      <title>Matrix action on vectors</title>

      <p>
        Of course, Sage knows how to perform the action of a matrix on a vector.
      </p>
      <sage>
        <input>
          C; v1
        </input>
        <output>
          [2 1]
          [1 1]
          (2, 1)
        </output>
      </sage>
      <sage>
        <input>
          C*v1
        </input>
        <output>
          (5, 3)
        </output>
      </sage>
      <p>And if you get the sizes wrong, it will return an error.</p>
      <sage>
        <input>
          A; v1
        </input>
        <output>
          [ 1  2  3]
          [ 5  8 13]
          (2, 1)
        </output>
      </sage>
      <sage>
        <input>
          A*v1
        </input>
        <output>
          Error in lines 1-1
          ...
          TypeError: unsupported operand parent(s) for '*': 'Full MatrixSpace of 2 by 3 dense matrices over Integer Ring' and 'Ambient free module of rank 2 over the principal ideal domain Integer Ring'
        </output>
      </sage>
      <p>If you really need it, Sage can tell you about inverses.</p>
      <sage>
        <input>
          A.is_invertible()
        </input>
        <output>
          False
        </output>
      </sage>
      <sage>
        <input>
          C.is_invertible()
        </input>
        <output>
          True
        </output>
      </sage>
      <sage>
        <input>
          C.inverse()
        </input>
        <output>
          [ 1 -1]
          [-1  2]
        </output>
      </sage>
    </subsubsection>
  </subsection>

  <subsection>
    <title>Exercises</title>

    <task>
      <statement>
        <p>
          Make an example of a matrix <m>\left(\begin{smallmatrix} 1 &amp;
          \bullet \\ -1 &amp; \bullet \end{smallmatrix}\right)</m> so that the
          equation<me>
          \begin{pmatrix} 1 &amp; \bullet \\ -1 &amp; \bullet \end{pmatrix}
          \begin{pmatrix} x \\ y \end{pmatrix} = \begin{pmatrix} 1 \\ -1
          \end{pmatrix}
          </me>
          has exactly one solution, or explain why this is not possible.
        </p>
        <p>
          Interpret this as a statement about <m>2</m>-vectors and draw the
          picture which corresponds.
        </p>
      </statement>
    </task>

    <task>
      <statement>
        <p>
          Make an example of a matrix <m>\left(\begin{smallmatrix} 4 &amp;
          8 &amp; \bullet \\ 3 &amp; 6 &amp; \bullet \\ 1 &amp; 2 &amp;
          \bullet \end{smallmatrix}\right)</m> so that the equation<me>
            \begin{pmatrix} 4 &amp; 8 &amp; \bullet \\ 3 &amp; 6 &amp; \bullet \\ 1 &amp; 2 &amp; \bullet \end{pmatrix} \begin{pmatrix} x \\ y \\ z \end{pmatrix} = \begin{pmatrix} 8 \\ 6 \\ 2 \end{pmatrix}
          </me>
          has exactly one solution, or explain why this is not possible.
        </p>
        <p>
          Interpret this as a statment about <m>3</m>-vectors and draw the
          picture which corresponds.
        </p>
      </statement>
    </task>

    <task>
      <statement>
        <p>
          Make an example of a matrix <m>\left( \begin{smallmatrix} 2 &amp; -1 \\
          \bullet &amp; \bullet \end{smallmatrix}\right)</m> so that the equation<me>
            \begin{pmatrix} 2 &amp; -1 \\ \bullet &amp; \bullet \end{pmatrix}
            \begin{pmatrix} x \\ y \end{pmatrix} = \begin{pmatrix} 7 \\ 3
            \end{pmatrix}
          </me>
          has exactly one solution, or explain why this is not possible.
        </p>
        <p>
          Interpret this as a statement about a pair of lines in the plane and
          draw the picture which corresponds.
        </p>
      </statement>
    </task>

    <task>
      <statement>
        <p>
          Make an example of a matrix <m>\left( \begin{smallmatrix} 1 &amp; 0
          &amp; 1\\ 1 &amp; 1 &amp; 3 \\ \bullet &amp; \bullet &amp; \bullet
          \end{smallmatrix}\right)</m> so that the equation<me>
            \begin{pmatrix} 1 &amp; 0 &amp; 1\\ 1 &amp; 1 &amp; 3 \\ \bullet
            &amp; \bullet &amp; \bullet \end{pmatrix}\begin{pmatrix} x \\ y \\ z
            \end{pmatrix} = \begin{pmatrix} 1 \\ 1 \\ 1 \end{pmatrix}
          </me>
          has no solutions, or explain why this is not possible.
        </p>
        <p>
          Interpret this as a statement about a planes in space and
          draw the picture which corresponds.
        </p>
      </statement>
    </task>

    <task>
      <statement>
        <p>
          Find a triple of numbers <m>x</m>, <m>y</m>, and <m>z</m> so that the
          linear combination<me>
            x \begin{pmatrix} 1 \\ 2 \\ 3 \end{pmatrix} +
            y \begin{pmatrix} 4 \\ 5\\ 6 \end{pmatrix} +
            z \begin{pmatrix} 7 \\ 8 \\ 9 \end{pmatrix}
          </me>
          yields the zero vector, or explain why this is not possible.
        </p>
        <p>
          Rewrite the above as an equation which involves a matrix.
        </p>
        <p>
          Plot the three vectors and describe the geometry of the situation.
        </p>
      </statement>
    </task>

    <task>
      <statement>
        <p>
          The vectors<me>
            r_1 = \begin{pmatrix} 1 \\ 4 \\ 7 \end{pmatrix}, \qquad
            r_2 = \begin{pmatrix} 2 \\ 5 \\ 8 \end{pmatrix}, \quad \text{ and } \quad
            r_3 = \begin{pmatrix} 3 \\ 6 \\ 9 \end{pmatrix}
          </me>
          are linearly dependent because they lie in a common plane (through
          the origin). Find a normal vector to this plane.
        </p>
        <p>
          Since the vectors are linearly dependent, there must be (infinitely)
          many choices of scalars <m>x</m>, <m>y</m>, and <m>z</m> so that
          <m>x r_1 + y r_2 + z r_3 = 0</m>. Find two sets of such numbers.
        </p>
      </statement>
    </task>

    <task>
      <statement>
        <p>
          Consider the equation<me>
            \begin{pmatrix} 2 &amp; 1 \\ 1 &amp; 1 \end{pmatrix}
            \begin{pmatrix} x \\ y \end{pmatrix} = \begin{pmatrix} b_1 \\ b_2
            \end{pmatrix}.
          </me>
          We are interested in being able to solve this for <m>x</m> and <m>y</m>
          for any given choice of the numbers <m>b_1</m> and <m>b_2</m>.
          Figure out a way to do this by writing <m>x</m> and <m>y</m> in terms
          of <m>b_1</m> and <m>b_2</m>.
        </p>
        <p>
          Rewrite your solution in the form<me>
            \begin{pmatrix} x \\ y \end{pmatrix} = b_1 \begin{pmatrix}
            \bullet \\ \bullet\end{pmatrix} + b_2 \begin{pmatrix}  \bullet
            \\ \bullet \end{pmatrix}.
          </me>
        </p>
        <p>
          How is this related to the inverse of the matrix
          <m>A = \left( \begin{smallmatrix} 2 &amp; 1 \\ 1 &amp; 1
          \end{smallmatrix} \right)</m>?
        </p>
      </statement>
    </task>

    <task>
      <statement>
        <p>
          Find an example of a number <m>c</m> and a vector <m>\left(
          \begin{smallmatrix} b_1 \\ b_2 \end{smallmatrix}\right)</m>
          so that the equation<me>
            \begin{pmatrix} 3 &amp; 51 \\ c &amp; 17 \end{pmatrix}
            \begin{pmatrix} x \\ y \end{pmatrix} =
            \begin{pmatrix} b_1 \\ b_2 \end{pmatrix}
          </me>
          does not have a solution, or explain why no such example exists.
        </p>
        <p>
          Explain your solution in terms of
          <ul>
            <li>lines in the plane,</li>
            <li><m>2</m>-vectors and linear combinations, and</li>
            <li>invertibility of a matrix.</li>
          </ul>
        </p>
      </statement>
    </task>

  </subsection>


</section>
